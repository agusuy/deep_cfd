{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Conv2D, ConvLSTM2D, MaxPool3D, UpSampling3D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "\n",
    "DATASET_FILE = \"../dataset/dataset_small_140224.npy\"\n",
    "\n",
    "dataset_original = np.load(DATASET_FILE)\n",
    "#################################\n",
    "dataset_original = dataset_original[:2, ...]\n",
    "#################################\n",
    "print(dataset_original.shape)\n",
    "\n",
    "dataset_original = np.float32(dataset_original)\n",
    "\n",
    "# Add a channel dimension\n",
    "dataset_original = np.expand_dims(dataset_original, axis=-1)\n",
    "\n",
    "# Normalize data\n",
    "print(np.min(dataset_original), np.max(dataset_original), np.mean(dataset_original), np.median(dataset_original), np.var(dataset_original))\n",
    "scaler = MinMaxScaler()\n",
    "dataset_original = scaler.fit_transform(dataset_original.reshape(-1, dataset_original.shape[-1])).reshape(dataset_original.shape)\n",
    "print(np.min(dataset_original), np.max(dataset_original), np.mean(dataset_original), np.median(dataset_original), np.var(dataset_original))\n",
    "\n",
    "# print(dataset_original.shape)\n",
    "NUM_SEQUENCES = dataset_original.shape[0]\n",
    "LENGHT_SEQUENCE = dataset_original.shape[1]\n",
    "WIDTH = dataset_original.shape[2]\n",
    "HEIGHT = dataset_original.shape[3]\n",
    "# print(NUM_SEQUENCES, LENGHT_SEQUENCE, WIDTH, HEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW = 5\n",
    "\n",
    "sliced_dataset = dataset_original.reshape(-1, WINDOW, dataset_original.shape[2], dataset_original.shape[3], 1)\n",
    "print(sliced_dataset.shape)\n",
    "\n",
    "# Split into train and validation sets using indexing to optimize memory.\n",
    "indexes = np.arange(sliced_dataset.shape[0])\n",
    "np.random.shuffle(indexes)\n",
    "train_index = indexes[: int(0.9 * sliced_dataset.shape[0])]\n",
    "val_index = indexes[int(0.9 * sliced_dataset.shape[0]) :]\n",
    "train_dataset = sliced_dataset[train_index]\n",
    "val_dataset = sliced_dataset[val_index]\n",
    "\n",
    "print(train_dataset.shape)\n",
    "print(val_dataset.shape)\n",
    "\n",
    "X_train, y_train = train_dataset[:,:-1,:,:,:], train_dataset[:,-1:,:,:,:]\n",
    "X_val, y_val = val_dataset[:,:-1,:,:,:], val_dataset[:,-1:,:,:,:]\n",
    "\n",
    "print(str(X_train.shape) + \", \" + str(y_train.shape))\n",
    "print(str(X_val.shape) + \", \" + str(y_val.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "GPUS = [\"GPU:0\",\"GPU:1\"]\n",
    "strategy = tf.distribute.MirroredStrategy(GPUS)\n",
    "\n",
    "with strategy.scope():\n",
    "    input_dimensions = X_train[0].shape\n",
    "\n",
    "    # Encoder\n",
    "    input = Input(input_dimensions)\n",
    "    encoder = ConvLSTM2D(filters=64, kernel_size=(4,4), padding=\"same\",\n",
    "                        return_sequences=True, activation=\"relu\")(input)\n",
    "    encoder = MaxPool3D(pool_size=(2,2,2))(encoder)\n",
    "    encoder = ConvLSTM2D(filters=32, kernel_size=(3,3), padding=\"same\",\n",
    "                        return_sequences=True, activation=\"relu\")(encoder)\n",
    "    encoder = MaxPool3D(pool_size=(2,2,2))(encoder)\n",
    "    encoder = ConvLSTM2D(filters=32, kernel_size=(2,2), padding=\"same\",\n",
    "                        return_sequences=True, activation=\"relu\", name='encoder_output')(encoder)\n",
    "\n",
    "    # Decoder 1 (sequence)\n",
    "    decoder_1 = ConvLSTM2D(filters=32, kernel_size=(2,2), padding=\"same\",\n",
    "                        return_sequences=True, activation=\"relu\")(encoder)\n",
    "    decoder_1 = UpSampling3D(size=(2,2,2))(decoder_1)\n",
    "    decoder_1 = ConvLSTM2D(filters=32, kernel_size=(3,3), padding=\"same\",\n",
    "                        return_sequences=True, activation=\"relu\")(decoder_1)\n",
    "    decoder_1 = UpSampling3D(size=(2,2,2))(decoder_1)\n",
    "    decoder_1 = ConvLSTM2D(filters=64, kernel_size=(4,4), padding=\"same\",\n",
    "                        return_sequences=True, activation=\"relu\")(decoder_1)\n",
    "    decoder_1 = Conv2D(filters=1, kernel_size=(4,4), padding=\"same\",\n",
    "                        activation=\"relu\", name='decoder_1_output')(decoder_1)\n",
    "\n",
    "\n",
    "    # model = Model(inputs=input, outputs=[decoder_1, decoder_2])\n",
    "    model = Model(inputs=input, outputs=decoder_1)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "                    # X_train, [X_train, y_train],\n",
    "                    X_train, X_train, \n",
    "                    # validation_data=(X_val, [X_val, y_val]),\n",
    "                    # validation_data=(X_val, X_val),\n",
    "                    batch_size=batch_size, epochs=10,\n",
    "                    verbose=1)\n",
    "\n",
    "model.save(f\"./models/_model_{datetime.now():%Y%m%d_%H%M%S}.h5\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'][2:])\n",
    "plt.title('decoder 1 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "# plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plt.plot(history.history['decoder_1_output_loss'])\n",
    "# plt.plot(history.history['val_decoder_1_output_loss'])\n",
    "# plt.title('decoder 1 loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(history.history['decoder_2_output_loss'])\n",
    "# plt.plot(history.history['val_decoder_2_output_loss'])\n",
    "# plt.title('decoder 2 loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model(\"./_model.h5\")\n",
    "model = load_model(\"./models/_model_20240218_215951.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_val, X_val)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Encoder-Decoder\n",
    "example_sequence = X_train[100].copy()\n",
    "print(\"example_sequence:\", np.min(example_sequence), np.max(example_sequence), np.mean(example_sequence), np.median(example_sequence), np.var(example_sequence))\n",
    "\n",
    "predicted_sequence = model.predict(np.expand_dims(example_sequence, axis=0), verbose=0)[0]\n",
    "print(\"predicted_sequence:\", np.min(predicted_sequence), np.max(predicted_sequence), np.mean(predicted_sequence), np.median(predicted_sequence), np.var(predicted_sequence))\n",
    "\n",
    "color_map = plt.cm.jet\n",
    "color_map.set_bad(color='black')\n",
    "fig, axes = plt.subplots(1, 4, figsize=(10, 5))\n",
    "for idx, ax in enumerate(axes.flat):\n",
    "\n",
    "    example_frame = example_sequence[idx].copy()\n",
    "    example_frame[example_frame==0.0] = np.nan\n",
    "\n",
    "    ax.imshow(np.squeeze(example_frame).transpose(), cmap=color_map)\n",
    "    ax.set_title(f\"Example Frame {idx + 1}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "color_map = plt.cm.jet\n",
    "color_map.set_bad(color='black')\n",
    "fig, axes = plt.subplots(1, 4, figsize=(10, 5))\n",
    "for idx, ax in enumerate(axes.flat):\n",
    "    \n",
    "    example_frame = example_sequence[idx]\n",
    "    example_frame_min=np.min(example_frame[example_frame!=0])\n",
    "    example_frame_max=np.max(example_frame)\n",
    "    \n",
    "    predicted_frame = predicted_sequence[idx]\n",
    "    predicted_frame[predicted_frame==0.0] = np.nan\n",
    "    predicted_frame[predicted_frame<example_frame_min] = np.nan\n",
    "    predicted_frame[predicted_frame>example_frame_max] = np.nan\n",
    "\n",
    "    ax.imshow(np.squeeze(predicted_frame).transpose(), cmap=color_map)\n",
    "    ax.set_title(f\"Predicted Frame {idx + 1}\")\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sequence = X_train[100].copy()\n",
    "example_frame = example_sequence[0].copy()\n",
    "print(\"example_frame:\", np.min(example_frame), np.max(example_frame), np.mean(example_frame), np.median(example_frame), np.var(example_frame))\n",
    "\n",
    "color_map = plt.cm.jet\n",
    "color_map.set_bad(color='black')\n",
    "example_frame[example_frame==0.0] = np.nan\n",
    "\n",
    "plt.clf()\n",
    "plt.imshow(np.squeeze(example_frame).transpose(), cmap=color_map)\n",
    "plt.title(f\"Example Frame\")\n",
    "plt.colorbar(label=\"Velocity\", orientation=\"horizontal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sequence = X_train[100].copy()\n",
    "example_frame = example_sequence[0].copy()\n",
    "print(\"example_frame:\", np.min(example_frame), np.max(example_frame), np.mean(example_frame), np.median(example_frame), np.var(example_frame))\n",
    "\n",
    "predicted_sequence = model.predict(np.expand_dims(example_sequence, axis=0), verbose=0)[0]\n",
    "predicted_frame = predicted_sequence[0]\n",
    "\n",
    "print(\"predicted_frame:\", np.min(predicted_frame), np.max(predicted_frame), np.mean(predicted_frame), np.median(predicted_frame), np.var(predicted_frame))\n",
    "\n",
    "example_frame_min=np.min(example_frame[example_frame!=0])\n",
    "example_frame_max=np.max(example_frame)\n",
    "\n",
    "# print(np.min(example_sequence[0][example_sequence[0]!=0]), np.max(example_sequence[0]), np.mean(example_sequence[0]), np.median(example_sequence[0]), np.var(example_sequence[0]))\n",
    "# print(np.min(predicted_frame[predicted_frame!=0]), np.max(predicted_frame), np.mean(predicted_frame), np.median(predicted_frame), np.var(predicted_frame))\n",
    "\n",
    "color_map = plt.cm.jet\n",
    "color_map.set_bad(color='black')\n",
    "predicted_frame[predicted_frame==0.0] = np.nan\n",
    "\n",
    "predicted_frame[predicted_frame<example_frame_min] = np.nan\n",
    "predicted_frame[predicted_frame>example_frame_max] = np.nan\n",
    "\n",
    "plt.clf()\n",
    "plt.imshow(np.squeeze(predicted_frame).transpose(), cmap=color_map)\n",
    "plt.title(f\"Predicted Frame\")\n",
    "plt.colorbar(label=\"Velocity\", orientation=\"horizontal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sequence = X_train[100].copy()\n",
    "frame = example_sequence[0].copy()\n",
    "predicted_sequence = model.predict(np.expand_dims(example_sequence, axis=0), verbose=0)[0]\n",
    "predicted_frame = predicted_sequence[0]\n",
    "frame_min=np.min(frame[frame!=0])\n",
    "frame_max=np.max(frame)\n",
    "frame[frame==0.0] = np.nan\n",
    "predicted_frame[predicted_frame==0.0] = np.nan\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "a = np.hstack(frame.flatten())\n",
    "_ = plt.hist(a, bins='auto')  # arguments are passed to np.histogram\n",
    "plt.title(\"Histogram Example Frame\")\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "a = np.hstack(predicted_frame.flatten())\n",
    "_ = plt.hist(a, bins='auto')  # arguments are passed to np.histogram\n",
    "plt.title(\"Histogram Predicted Frame\")\n",
    "plt.show()\n",
    "\n",
    "predicted_frame[predicted_frame<frame_min] = np.nan\n",
    "predicted_frame[predicted_frame>frame_max] = np.nan\n",
    "\n",
    "plt.clf()\n",
    "a = np.hstack(predicted_frame.flatten())\n",
    "_ = plt.hist(a, bins='auto')  # arguments are passed to np.histogram\n",
    "plt.title(\"Histogram Predicted Frame -interval\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Encoder-Predict\n",
    "\n",
    "# example_input = X_val[1000]\n",
    "# example_output = y_val[1000]\n",
    "# new_prediction = model.predict(np.expand_dims(example_input, axis=0), verbose=0)[1][0]\n",
    "# print(example_input.shape)\n",
    "# print(example_output.shape)\n",
    "# print(new_prediction.shape)\n",
    "\n",
    "# fig, axes = plt.subplots(2, 10, figsize=(20, 4))\n",
    "\n",
    "# # Plot the original frames.\n",
    "# for idx, ax in enumerate(axes[0]):\n",
    "#     ax.imshow(np.squeeze(y_val[idx]), cmap=\"gray\")\n",
    "#     ax.set_title(f\"Sequence {idx + 1}\")\n",
    "#     ax.axis(\"off\")\n",
    "\n",
    "# # Plot the new frames.\n",
    "# for idx, ax in enumerate(axes[1]):\n",
    "#     new_prediction = model.predict(np.expand_dims(X_val[idx], axis=0), verbose=0)\n",
    "#     ax.imshow(np.squeeze(new_prediction[1][0]), cmap=\"gray\")\n",
    "#     ax.set_title(f\"Sequence {idx + 1}\")\n",
    "#     ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected_frames = []\n",
    "# predicted_frames = []\n",
    "\n",
    "# sequence = dataset_original[8000]\n",
    "# for i in range(len(sequence)-WINDOW):\n",
    "#     j = i+WINDOW\n",
    "#     slice = sequence[i:j]\n",
    "#     input = slice[0:WINDOW-1]\n",
    "#     expected_output = slice[WINDOW-1:]\n",
    "#     expected_frames.append(expected_output)\n",
    "#     new_prediction = model.predict(np.expand_dims(input, axis=0), verbose=0)[1][0]\n",
    "#     predicted_frames.append(new_prediction)\n",
    "\n",
    "# fig, axes = plt.subplots(2, 14, figsize=(20, 4))\n",
    "# # Plot the original frames.\n",
    "# for idx, ax in enumerate(axes[0]):\n",
    "#     ax.imshow(np.squeeze(expected_frames[idx]), cmap=\"gray\")\n",
    "#     ax.set_title(f\"Frame {idx + WINDOW}\")\n",
    "#     ax.axis(\"off\")\n",
    "\n",
    "# # Plot the new frames.\n",
    "# for idx, ax in enumerate(axes[1]):\n",
    "#     ax.imshow(np.squeeze(predicted_frames[idx]), cmap=\"gray\")\n",
    "#     ax.set_title(f\"Frame {idx + WINDOW}\")\n",
    "#     ax.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfd_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
