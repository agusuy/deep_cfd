{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Conv2D, ConvLSTM2D, MaxPool3D, UpSampling3D, LeakyReLU\n",
    "from keras.losses import MeanAbsoluteError, MeanSquaredError\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "\n",
    "# DATASET_FILE = \"../dataset/dataset_small_140224.npy\"\n",
    "DATASET_FILE = \"../dataset/dataset_smaller_270224.npy\"\n",
    "\n",
    "dataset_original = np.load(DATASET_FILE)\n",
    "print(dataset_original.shape)\n",
    "# print(dataset_original.nbytes/1000**3)\n",
    "#################################\n",
    "# dataset_original = dataset_original[:2, ...]\n",
    "#################################\n",
    "\n",
    "dataset_original = np.float32(dataset_original)\n",
    "\n",
    "# Add a channel dimension\n",
    "dataset_original = np.expand_dims(dataset_original, axis=-1)\n",
    "\n",
    "# Normalize data\n",
    "print(np.min(dataset_original), np.max(dataset_original), np.mean(dataset_original), np.median(dataset_original), np.var(dataset_original))\n",
    "dataset_original[dataset_original==-1] = np.nan\n",
    "scaler = MinMaxScaler()\n",
    "dataset_original = scaler.fit_transform(dataset_original.reshape(-1, dataset_original.shape[-1])).reshape(dataset_original.shape)\n",
    "print(np.nanmin(dataset_original), np.nanmax(dataset_original), np.nanmean(dataset_original), np.nanmedian(dataset_original), np.nanvar(dataset_original))\n",
    "dataset_original[np.isnan(dataset_original)] = -1\n",
    "print(np.min(dataset_original), np.max(dataset_original), np.mean(dataset_original), np.median(dataset_original), np.var(dataset_original))\n",
    "\n",
    "# print(dataset_original.shape)\n",
    "NUM_SEQUENCES = dataset_original.shape[0]\n",
    "LENGHT_SEQUENCE = dataset_original.shape[1]\n",
    "WIDTH = dataset_original.shape[2]\n",
    "HEIGHT = dataset_original.shape[3]\n",
    "# print(NUM_SEQUENCES, LENGHT_SEQUENCE, WIDTH, HEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW = 5\n",
    "\n",
    "# Split into train and validation sets using indexing to optimize memory.\n",
    "indexes = np.arange(dataset_original.shape[0])\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indexes)\n",
    "train_index = indexes[: int(0.9 * dataset_original.shape[0])]\n",
    "val_index = indexes[int(0.9 * dataset_original.shape[0]) :]\n",
    "train_dataset = dataset_original[train_index]\n",
    "val_dataset = dataset_original[val_index]\n",
    "\n",
    "print(train_dataset.shape)\n",
    "print(val_dataset.shape)\n",
    "\n",
    "train_dataset = train_dataset.reshape(-1, WINDOW, train_dataset.shape[2], train_dataset.shape[3], 1)\n",
    "val_dataset = val_dataset.reshape(-1, WINDOW, val_dataset.shape[2], val_dataset.shape[3], 1)\n",
    "\n",
    "print(train_dataset.shape)\n",
    "print(val_dataset.shape)\n",
    "\n",
    "X_train, y_train = train_dataset[:,:-1,:,:,:], train_dataset[:,-1:,:,:,:]\n",
    "X_val, y_val = val_dataset[:,:-1,:,:,:], val_dataset[:,-1:,:,:,:]\n",
    "\n",
    "print(str(X_train.shape) + \", \" + str(y_train.shape))\n",
    "print(str(X_val.shape) + \", \" + str(y_val.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# session = tf.Session(config=config)\n",
    "\n",
    "\n",
    "# from tensorflow.python.client import device_lib\n",
    "# local_device_protos=device_lib.list_local_devices()\n",
    "# [x.name for x in local_device_protos if x.device_type == 'GPU' or x.device_type == 'CPU']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "GPUS = [\"GPU:0\",\"GPU:1\"]\n",
    "# GPUS = [\"GPU:0\"]\n",
    "strategy = tf.distribute.MirroredStrategy(GPUS)\n",
    "\n",
    "with strategy.scope():\n",
    "    input_dimensions = X_train[0].shape\n",
    "\n",
    "    # Encoder\n",
    "    input = Input(input_dimensions)\n",
    "    encoder = ConvLSTM2D(filters=64, kernel_size=(4,4), padding=\"same\",\n",
    "                        return_sequences=True, activation=\"relu\")(input)\n",
    "    encoder = MaxPool3D(pool_size=(2,2,2))(encoder)\n",
    "    encoder = ConvLSTM2D(filters=32, kernel_size=(3,3), padding=\"same\",\n",
    "                        return_sequences=True, activation=\"relu\")(encoder)\n",
    "    encoder = MaxPool3D(pool_size=(2,2,2))(encoder)\n",
    "    encoder = ConvLSTM2D(filters=32, kernel_size=(2,2), padding=\"same\",\n",
    "                        return_sequences=True, activation=\"relu\", name='encoder_output')(encoder)\n",
    "\n",
    "    # Decoder\n",
    "    decoder = ConvLSTM2D(filters=32, kernel_size=(2,2), padding=\"same\",\n",
    "                        return_sequences=True, activation=\"relu\")(encoder)\n",
    "    decoder = UpSampling3D(size=(2,2,2))(decoder)\n",
    "    decoder = ConvLSTM2D(filters=32, kernel_size=(3,3), padding=\"same\",\n",
    "                        return_sequences=True, activation=\"relu\")(decoder)\n",
    "    decoder = UpSampling3D(size=(2,2,2))(decoder)\n",
    "    decoder = ConvLSTM2D(filters=64, kernel_size=(4,4), padding=\"same\",\n",
    "                        return_sequences=True, activation=\"relu\")(decoder)\n",
    "    decoder = Conv2D(filters=1, kernel_size=(4,4), padding=\"same\",\n",
    "                        activation=LeakyReLU(), \n",
    "                        name='decoder_output')(decoder)\n",
    "\n",
    "    # Predictor\n",
    "    predictor = ConvLSTM2D(filters=32, kernel_size=(3,3), padding=\"same\",\n",
    "                        return_sequences=True, activation=\"relu\")(encoder)\n",
    "    predictor = UpSampling3D(size=(2,2,2))(predictor)\n",
    "    predictor = ConvLSTM2D(filters=64, kernel_size=(3,3), padding=\"same\",\n",
    "                        return_sequences=True, activation=\"relu\")(predictor)\n",
    "    predictor = UpSampling3D(size=(2,2,2))(predictor)\n",
    "    predictor = ConvLSTM2D(filters=64, kernel_size=(3,3), padding=\"same\",\n",
    "                        return_sequences=True, activation=\"relu\")(predictor)\n",
    "    predictor = Conv2D(filters=1, kernel_size=(3,3), padding=\"same\", \n",
    "                        activation=LeakyReLU())(predictor)\n",
    "    predictor = MaxPool3D(pool_size=(4,1,1), name='predictor_output')(predictor)\n",
    "\n",
    "\n",
    "\n",
    "    model = Model(inputs=input, \n",
    "                  outputs=[decoder, predictor]\n",
    "                  # outputs=decoder\n",
    "                )\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss=MeanSquaredError())\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_memory_usage(batch_size, model):\n",
    "    import numpy as np\n",
    "    try:\n",
    "        from keras import backend as K\n",
    "    except:\n",
    "        from tensorflow.keras import backend as K\n",
    "\n",
    "    shapes_mem_count = 0\n",
    "    internal_model_mem_count = 0\n",
    "    for l in model.layers:\n",
    "        layer_type = l.__class__.__name__\n",
    "        if layer_type == 'Model':\n",
    "            internal_model_mem_count += get_model_memory_usage(batch_size, l)\n",
    "        single_layer_mem = 1\n",
    "        out_shape = l.output_shape\n",
    "        if type(out_shape) is list:\n",
    "            out_shape = out_shape[0]\n",
    "        for s in out_shape:\n",
    "            if s is None:\n",
    "                continue\n",
    "            single_layer_mem *= s\n",
    "        shapes_mem_count += single_layer_mem\n",
    "\n",
    "    trainable_count = np.sum([K.count_params(p) for p in model.trainable_weights])\n",
    "    non_trainable_count = np.sum([K.count_params(p) for p in model.non_trainable_weights])\n",
    "\n",
    "    number_size = 4.0\n",
    "    if K.floatx() == 'float16':\n",
    "        number_size = 2.0\n",
    "    if K.floatx() == 'float64':\n",
    "        number_size = 8.0\n",
    "\n",
    "    total_memory = number_size * (batch_size * shapes_mem_count + trainable_count + non_trainable_count)\n",
    "    gbytes = np.round(total_memory / (1024.0 ** 3), 3) + internal_model_mem_count\n",
    "    return gbytes\n",
    "\n",
    "\n",
    "get_model_memory_usage(batch_size, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    # epochs = 4\n",
    "    epochs = 400\n",
    "    history = model.fit(\n",
    "                        X_train, [X_train, y_train],\n",
    "                        # X_train, X_train, \n",
    "                        # validation_data=(X_val, [X_val, y_val]),\n",
    "                        # validation_data=(X_val, X_val),\n",
    "                        batch_size=batch_size, epochs=epochs,\n",
    "                        verbose=1)\n",
    "\n",
    "model_name = f\"./models/_model_{datetime.now():%Y%m%d_%H%M%S}\"\n",
    "\n",
    "model.save(model_name + \".h5\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "fig.suptitle('Training loss')\n",
    "\n",
    "ax1.plot(history.history['decoder_output_loss'][2:])\n",
    "ax1.set_title('Autoencoder loss')\n",
    "ax1.set_ylabel('loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "# plt.legend(['train'], loc='upper left')\n",
    "\n",
    "ax2.plot(history.history['predictor_output_loss'][2:])\n",
    "ax2.set_title('Predictor loss')\n",
    "ax2.set_ylabel('loss')\n",
    "ax2.set_xlabel('epoch')\n",
    "# plt.legend(['train'], loc='upper left')\n",
    "plt.tight_layout()\n",
    "fig.savefig(model_name + \"_training.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model(\"./models/_model_20240229_184755.h5\")\n",
    "model = load_model(\"./models/v3_model_20240228_170815.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_val, [X_val, y_val])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Encoder-Decoder\n",
    "example_sequence = X_train[100].copy()\n",
    "print(\"example_sequence:\", np.min(example_sequence), np.max(example_sequence), np.mean(example_sequence), np.median(example_sequence), np.var(example_sequence))\n",
    "\n",
    "predicted_sequence = model.predict(np.expand_dims(example_sequence, axis=0), verbose=0)[0]\n",
    "print(\"predicted_sequence:\", np.min(predicted_sequence), np.max(predicted_sequence), np.mean(predicted_sequence), np.median(predicted_sequence), np.var(predicted_sequence))\n",
    "\n",
    "\n",
    "color_map = plt.cm.jet\n",
    "color_map.set_bad(color='black')\n",
    "fig, axes = plt.subplots(1, 4, figsize=(40, 20))\n",
    "for idx, ax in enumerate(axes.flat):\n",
    "\n",
    "    example_frame = example_sequence[idx].copy()\n",
    "    example_frame[example_frame==-1] = np.nan\n",
    "\n",
    "    ax.imshow(np.squeeze(example_frame).transpose(), cmap=color_map)\n",
    "    ax.set_title(f\"Original Frame {idx + 1}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "color_map = plt.cm.jet\n",
    "color_map.set_bad(color='black')\n",
    "fig, axes = plt.subplots(1, 4, figsize=(40, 20))\n",
    "for idx, ax in enumerate(axes.flat):\n",
    "    \n",
    "    example_frame = example_sequence[idx]\n",
    "    example_frame_min=np.min(example_frame[example_frame!=0])\n",
    "    example_frame_max=np.max(example_frame)\n",
    "    \n",
    "    predicted_frame = predicted_sequence[0][idx]\n",
    "    predicted_frame[predicted_frame<0.0] = np.nan\n",
    "    predicted_frame[predicted_frame<example_frame_min] = np.nan\n",
    "    predicted_frame[predicted_frame>example_frame_max] = np.nan\n",
    "\n",
    "    ax.imshow(np.squeeze(predicted_frame).transpose(), cmap=color_map)\n",
    "    ax.set_title(f\"Decoded Frame {idx + 1}\")\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sequence = X_train[100].copy()\n",
    "example_frame = example_sequence[0].copy()\n",
    "print(\"example_frame:\", np.min(example_frame), np.max(example_frame), np.mean(example_frame), np.median(example_frame), np.var(example_frame))\n",
    "\n",
    "color_map = plt.cm.jet\n",
    "color_map.set_bad(color='black')\n",
    "example_frame[example_frame==-1] = np.nan\n",
    "\n",
    "plt.clf()\n",
    "plt.imshow(np.squeeze(example_frame).transpose(), cmap=color_map)\n",
    "plt.title(f\"Original Frame\")\n",
    "plt.colorbar(label=\"Velocity\", orientation=\"horizontal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sequence = X_train[100].copy()\n",
    "example_frame = example_sequence[0].copy()\n",
    "print(\"example_frame:\", np.min(example_frame), np.max(example_frame), np.mean(example_frame), np.median(example_frame), np.var(example_frame))\n",
    "\n",
    "predicted_sequence = model.predict(np.expand_dims(example_sequence, axis=0), verbose=0)[0]\n",
    "predicted_frame = predicted_sequence[0][0]\n",
    "\n",
    "print(\"predicted_frame:\", np.min(predicted_frame), np.max(predicted_frame), np.mean(predicted_frame), np.median(predicted_frame), np.var(predicted_frame))\n",
    "\n",
    "example_frame_min=np.min(example_frame[example_frame!=-1])\n",
    "example_frame_max=np.max(example_frame)\n",
    "\n",
    "# print(example_frame_min, example_frame_max, np.mean(example_sequence[0]), np.median(example_sequence[0]), np.var(example_sequence[0]))\n",
    "# print(np.min(predicted_frame[predicted_frame>-1]), np.max(predicted_frame), np.mean(predicted_frame), np.median(predicted_frame), np.var(predicted_frame))\n",
    "\n",
    "color_map = plt.cm.jet\n",
    "color_map.set_bad(color='black')\n",
    "\n",
    "predicted_frame[predicted_frame<example_frame_min] = np.nan\n",
    "predicted_frame[predicted_frame>example_frame_max] = np.nan\n",
    "\n",
    "plt.clf()\n",
    "plt.imshow(np.squeeze(predicted_frame).transpose(), cmap=color_map)\n",
    "plt.title(f\"Decoded Frame\")\n",
    "plt.colorbar(label=\"Velocity\", orientation=\"horizontal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sequence = X_train[100].copy()\n",
    "frame = example_sequence[0].copy()\n",
    "predicted_sequence = model.predict(np.expand_dims(example_sequence, axis=0), verbose=0)[0]\n",
    "predicted_frame = predicted_sequence[0][0]\n",
    "frame_min=np.min(frame[frame!=-1])\n",
    "frame_max=np.max(frame)\n",
    "frame[frame==-1] = np.nan\n",
    "# predicted_frame[frame==-1] = np.nan\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "plt.hist(frame.flatten(), bins='auto')\n",
    "plt.title(\"Histogram Encoded Frame\")\n",
    "plt.xlabel('Velocity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# plt.clf()\n",
    "# plt.hist(predicted_frame.flatten(), bins='auto')\n",
    "# plt.title(\"Histogram Decoded Frame\")\n",
    "# plt.xlabel('Velocity')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()\n",
    "\n",
    "predicted_frame[predicted_frame<frame_min] = np.nan\n",
    "predicted_frame[predicted_frame>frame_max] = np.nan\n",
    "\n",
    "plt.clf()\n",
    "plt.hist(predicted_frame.flatten(), bins='auto')\n",
    "plt.title(\"Histogram Decoded Frame\")\n",
    "plt.xlabel('Velocity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sequence = X_train[100].copy()\n",
    "frame = example_sequence[0].copy()\n",
    "predicted_sequence = model.predict(np.expand_dims(example_sequence, axis=0), verbose=0)[0]\n",
    "predicted_frame = predicted_sequence[0][0]\n",
    "frame_min=np.min(frame[frame!=-1])\n",
    "frame_max=np.max(frame)\n",
    "\n",
    "frame_data = frame.flatten()\n",
    "predicted_data = predicted_frame.flatten()\n",
    "\n",
    "frame_data = np.delete(frame_data, np.where(frame_data == -1))\n",
    "\n",
    "predicted_data = np.delete(predicted_data, np.where(predicted_data<frame_min))\n",
    "predicted_data = np.delete(predicted_data, np.where(predicted_data>frame_max))\n",
    "\n",
    "\n",
    "hist_frame, bin_edges_frame = np.histogram(frame_data, bins='auto')\n",
    "bin_center_frame = (bin_edges_frame[:-1] + bin_edges_frame[1:])/2\n",
    "hist_predicted, bin_edges_predicted = np.histogram(predicted_data, bins='auto')\n",
    "bin_center_predicted = (bin_edges_predicted[:-1] + bin_edges_predicted[1:])/2\n",
    "\n",
    "plt.figure()\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.errorbar(bin_center_frame, hist_frame, yerr=0, fmt='.', color=\"green\")\n",
    "plt.errorbar(bin_center_predicted, hist_predicted, yerr=0, fmt='|', color=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sequence = X_train[100].copy()\n",
    "frame = example_sequence[0].copy()\n",
    "predicted_sequence = model.predict(np.expand_dims(example_sequence, axis=0), verbose=0)[0]\n",
    "predicted_frame = predicted_sequence[0][0]\n",
    "\n",
    "# residual = np.abs(frame - predicted_frame)\n",
    "residual = np.square(frame - predicted_frame)\n",
    "\n",
    "plt.clf()\n",
    "plt.imshow(np.squeeze(residual).transpose(), cmap=\"Grays\")\n",
    "plt.colorbar(label=\"error\", orientation=\"horizontal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Encoder-Predict\n",
    "\n",
    "# example_sequence = X_val[100].copy()\n",
    "# example_output = y_val[100].copy()\n",
    "# predicted_frame = model.predict(np.expand_dims(example_sequence, axis=0), verbose=0)[1][0]\n",
    "# print(example_sequence.shape)\n",
    "# print(example_output.shape)\n",
    "# print(predicted_frame.shape)\n",
    "\n",
    "\n",
    "color_map = plt.cm.jet\n",
    "color_map.set_bad(color='black')\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(80, 20))\n",
    "# Plot the original frames.\n",
    "for idx, ax in enumerate(axes[0]):\n",
    "\n",
    "    example_frame = y_val[idx].copy()\n",
    "    example_frame[example_frame==-1] = np.nan\n",
    "\n",
    "    ax.imshow(np.squeeze(example_frame).transpose(), cmap=color_map)\n",
    "    ax.set_title(f\"Sequence {idx + 1}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "# Plot the new frames.\n",
    "for idx, ax in enumerate(axes[1]):\n",
    "\n",
    "    example_sequence = X_val[idx].copy()\n",
    "    example_frame = y_val[idx].copy()\n",
    "\n",
    "    predicted_frame = model.predict(np.expand_dims(example_sequence, axis=0), verbose=0)[1][0]\n",
    "    \n",
    "    predicted_frame[predicted_frame<0.0] = np.nan\n",
    "\n",
    "    ax.imshow(np.squeeze(predicted_frame).transpose(), cmap=color_map)\n",
    "    ax.set_title(f\"Sequence {idx + 1}\")\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_frames = []\n",
    "predicted_frames = []\n",
    "\n",
    "example_sequence = dataset_original[20].copy()\n",
    "# limit = len(sequence)-WINDOW\n",
    "limit = 20\n",
    "for i in range(limit):\n",
    "    i += 100\n",
    "\n",
    "    j = i+WINDOW\n",
    "    slice = example_sequence[i:j]\n",
    "    input = slice[0:WINDOW-1]\n",
    "    expected_output = slice[WINDOW-1:]\n",
    "    expected_frames.append(expected_output)\n",
    "    new_prediction = model.predict(np.expand_dims(input, axis=0), verbose=0)[1][0]\n",
    "    predicted_frames.append(new_prediction)\n",
    "\n",
    "\n",
    "color_map = plt.cm.jet\n",
    "color_map.set_bad(color='black')\n",
    "\n",
    "fig, axes = plt.subplots(2, limit, figsize=(30*limit, 15*2))\n",
    "# Plot the original frames.\n",
    "for idx, ax in enumerate(axes[0]):\n",
    "\n",
    "    example_frame = expected_frames[idx].copy()\n",
    "    example_frame[example_frame==-1] = np.nan\n",
    "\n",
    "    ax.imshow(np.squeeze(example_frame).transpose(), cmap=color_map)\n",
    "    ax.set_title(f\"Frame {idx + WINDOW}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "# Plot the new frames.\n",
    "for idx, ax in enumerate(axes[1]):\n",
    "\n",
    "    predicted_frame = predicted_frames[idx]\n",
    "    predicted_frame[predicted_frame<0.0] = np.nan\n",
    "\n",
    "    ax.imshow(np.squeeze(predicted_frame).transpose(), cmap=color_map)\n",
    "    ax.set_title(f\"Frame {idx + WINDOW}\")\n",
    "    ax.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.set_printoptions(threshold=np.inf)\n",
    "# np.set_printoptions(linewidth=np.inf)\n",
    "\n",
    "# WINDOW = 5\n",
    "\n",
    "# example_sequence = np.array([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19], dtype=np.float32)\n",
    "\n",
    "# predicted_sequence_size = example_sequence.size\n",
    "\n",
    "# predicted_sequence = np.zeros(predicted_sequence_size)\n",
    "\n",
    "# predicted_sequence[0:WINDOW-1] = example_sequence[0:WINDOW-1]\n",
    "\n",
    "# print(example_sequence)\n",
    "# print(predicted_sequence)\n",
    "\n",
    "# for i in range(predicted_sequence_size-WINDOW+1):\n",
    "\n",
    "#     input = predicted_sequence[i:i+WINDOW-1]\n",
    "    \n",
    "#     #####prediction######\n",
    "#     predicted_frame = input[-1] + 1\n",
    "#     #####################\n",
    "\n",
    "#     predicted_sequence[i+WINDOW-1] = predicted_frame\n",
    "\n",
    "# print(example_sequence)\n",
    "# print(predicted_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sequence = dataset_original[3].copy()\n",
    "\n",
    "predicted_sequence_size = len(example_sequence)\n",
    "dim=example_sequence.shape\n",
    "\n",
    "predicted_sequence = np.zeros(dim)\n",
    "\n",
    "predicted_sequence[0:WINDOW-1] = example_sequence[0:WINDOW-1]\n",
    "\n",
    "frame_residual = 0\n",
    "total_residual = 0\n",
    "\n",
    "for i in range(predicted_sequence_size-WINDOW+1):\n",
    "    # input = predicted_sequence[i:i+WINDOW-1]\n",
    "    input = example_sequence[i:i+WINDOW-1]\n",
    "\n",
    "    predicted_frame = model.predict(np.expand_dims(input, axis=0), verbose=0)[1][0]\n",
    "\n",
    "    predicted_sequence[i+WINDOW-1] = predicted_frame\n",
    "\n",
    "print(example_sequence.shape)\n",
    "print(predicted_sequence.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = plt.cm.jet\n",
    "color_map.set_bad(color='black')\n",
    "\n",
    "limit=40\n",
    "fig, axes = plt.subplots(2, limit, figsize=(10*limit, 5*2))\n",
    "# fig, axes = plt.subplots(limit, 2, figsize=(5*2, 10*limit))\n",
    "\n",
    "# Plot the original frames.\n",
    "for idx, ax in enumerate(axes[0]):\n",
    "\n",
    "    example_frame = example_sequence[idx].copy()\n",
    "    example_frame[example_frame==-1] = np.nan\n",
    "\n",
    "    ax.imshow(np.squeeze(example_frame).transpose(), cmap=color_map)\n",
    "    ax.set_title(f\"Frame {idx}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "# Plot the new frames.\n",
    "for idx, ax in enumerate(axes[1]):\n",
    "\n",
    "    predicted_frame = predicted_sequence[idx].copy()\n",
    "    predicted_frame[predicted_frame<0.0] = np.nan\n",
    "\n",
    "    ax.imshow(np.squeeze(predicted_frame).transpose(), cmap=color_map)\n",
    "    ax.set_title(f\"Frame {idx}\")\n",
    "    ax.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = plt.cm.jet\n",
    "color_map.set_bad(color='black')\n",
    "\n",
    "idx = 100\n",
    "\n",
    "_, axes = plt.subplots(2, 1)\n",
    "\n",
    "# original\n",
    "example_frame = example_sequence[idx].copy()\n",
    "example_frame[example_frame==-1] = np.nan \n",
    "axes[0].imshow(np.squeeze(example_frame).transpose(), cmap=color_map)\n",
    "axes[0].title.set_text('Original')\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "\n",
    "# generated\n",
    "predicted_frame = predicted_sequence[idx].copy()\n",
    "predicted_frame[predicted_frame<0.0] = np.nan\n",
    "axes[1].imshow(np.squeeze(predicted_frame).transpose(), cmap=color_map)\n",
    "axes[1].title.set_text('Generated')\n",
    "axes[1].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfd_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
